"""
Petrophysical Models Module

Core petrophysical calculations including Archie's equation and Relative Rock Properties models.
Extracted from advanced_preprocessing_system10.py for modular architecture.
"""

import numpy as np
import warnings
from typing import Dict, List, Optional, Tuple, Any

# Import constants
from petrophysics.constants import PetrophysicalConstants, PHYSICAL_CONSTANTS

# Check for optional scientific libraries
SCIPY_AVAILABLE = False
SKLEARN_AVAILABLE = False

try:
    from scipy import stats
    SCIPY_AVAILABLE = True
except ImportError:
    pass

try:
    from sklearn.linear_model import HuberRegressor
    SKLEARN_AVAILABLE = True
except ImportError:
    pass


#=============================================================================
# ARCHIE'S EQUATION AND PETROPHYSICAL CALCULATIONS
#=============================================================================

class ArchieEquationCalculator:
    """
    Implements Archie's equation utilities and related petrophysical calculations.
    Functions validate inputs, clamp outputs to physical ranges, and return
    structured results for downstream processing and reporting.
    """
    
    def __init__(self):
        # Archie's equation coefficients - industry standard values
        self.archie_a = 1.0      # Tortuosity factor (typical range: 0.6-2.0)
        self.archie_m = 2.0      # Cementation exponent (typical range: 1.8-2.5)
        self.archie_n = 2.0      # Saturation exponent (typical range: 1.8-2.4)
        self.rw = 0.05           # Formation water resistivity (ohm-m)
        
        # Matrix densities (g/cm³) - from Schlumberger Chartbook
        # Using midpoint values from the established ranges
        self.matrix_densities = {
            'sandstone': 2.675,   # Midpoint of 2.65-2.70 range
            'limestone': 2.775,   # Midpoint of 2.71-2.84 range  
            'dolomite': 2.875,    # Midpoint of 2.85-2.90 range
            'shale': 2.70         # Midpoint of 2.65-2.75 range
        }
    
    def calculate_water_saturation_archie(self, porosity: np.ndarray, 
                                        resistivity: np.ndarray,
                                        a: float = None, m: float = None, 
                                        n: float = None, rw: float = None) -> Dict[str, np.ndarray]:
        """
        Calculate water saturation using classic Archie's equation
        Formula: Sw = ((a * Rw) / (φᵐ * Rt))^(1/n)
        """
        a = a if a is not None else self.archie_a
        m = m if m is not None else self.archie_m
        n = n if n is not None else self.archie_n
        rw = rw if rw is not None else self.rw
        
        # Input validation with professional ranges
        # Porosity: 1% to 50% (0.01 to 0.5 fraction)
        # Resistivity: 0.1 to 10,000 ohm-m (covers saltwater to gas-filled rock)
        valid_mask = ((porosity > 0.01) & (porosity < 0.5) & 
                     (resistivity > 0.1) & (resistivity < 10000) &
                     ~np.isnan(porosity) & ~np.isnan(resistivity) & 
                     np.isfinite(porosity) & np.isfinite(resistivity))
        
        sw = np.full_like(porosity, np.nan)
        
        if np.any(valid_mask):
            valid_porosity = porosity[valid_mask]
            valid_resistivity = resistivity[valid_mask]
            
            # Archie's equation: Sw = ((a * Rw) / (φᵐ * Rt))^(1/n)
            # Corrected: Formation factor F = a / φᵐ, then Sw = (F * Rw / Rt)^(1/n)
            formation_factor = a / (valid_porosity ** m)
            sw_valid = ((formation_factor * rw) / valid_resistivity) ** (1/n)
            sw_valid = np.clip(sw_valid, 0.0, 1.0)  # Physical bounds
            sw[valid_mask] = sw_valid
        
        return {
            'water_saturation': sw,
            'hydrocarbon_saturation': 1.0 - sw,
            'valid_points': np.sum(valid_mask),
            'parameters_used': {'a': a, 'm': m, 'n': n, 'rw': rw}
        }
    
    def calculate_porosity_density(self, bulk_density: np.ndarray, 
                                 matrix_density: float = 2.65,
                                 fluid_density: float = 1.0) -> Dict[str, np.ndarray]:
        """
        Calculate porosity from bulk density: φ = (ρma - ρb) / (ρma - ρfl)
        """
        valid_mask = ((bulk_density > 1.5) & (bulk_density < 3.5) & 
                     ~np.isnan(bulk_density))
        
        porosity = np.full_like(bulk_density, np.nan)
        
        if np.any(valid_mask):
            valid_density = bulk_density[valid_mask]
            porosity_valid = (matrix_density - valid_density) / (matrix_density - fluid_density)
            porosity_valid = np.clip(porosity_valid, 0.0, 0.5)  # Physical bounds
            porosity[valid_mask] = porosity_valid
        
        return {
            'porosity': porosity,
            'valid_points': np.sum(valid_mask),
            'parameters_used': {'matrix_density': matrix_density, 'fluid_density': fluid_density}
        }


#=============================================================================
# RELATIVE ROCK PROPERTIES MODEL - Alvaro Chaveste's Implementation
#=============================================================================

class RelativeRockPropertiesModel:
    """
    Relative Rock Properties (RRP) model for leveraging inter-curve relationships
    to estimate missing values. Trains pairwise relations (linear, power-law,
    quantile mapping) and selects the best relation per curve pair. Provides
    helpers to apply relationships and to ensemble predictions during large-gap fill.
    """
    
    def __init__(self):
        self.property_relations = {}
        self.trained = False
    
    def train(self, data_dict, formation_info=None):
        """Train the relative rock properties model using available data
        
        Args:
            data_dict: Dictionary of curve names to numpy arrays of data
            formation_info: Optional dictionary with formation tops and lithology
        """
        self.data_dict = data_dict
        self.formation_info = formation_info
        
        # Store curve names for convenience
        self.curve_names = list(data_dict.keys())
        
        # Calculate relationships between properties
        successful_relations = 0
        total_pairs = 0
        
        for i, curve1 in enumerate(self.curve_names):
            for j, curve2 in enumerate(self.curve_names):
                if i >= j:
                    continue
                
                total_pairs += 1
                relation_key = f"{curve1}_{curve2}"
                relation = self._compute_property_relation(
                    data_dict[curve1], data_dict[curve2]
                )
                self.property_relations[relation_key] = relation
                
                # Track successful model training
                if relation.get('type') not in ['insufficient_data', 'linear_failed', 'power_failed', 'quantile_failed']:
                    successful_relations += 1
        
        self.trained = True
        
        # Log training completion with quality summary
        if hasattr(self, 'log_processing'):
            self.log_processing(f"[MODEL TRAINING] RRP Model training complete")
            self.log_processing(f"   Curve Pairs Analyzed: {total_pairs}")
            self.log_processing(f"   Successful Relations: {successful_relations}/{total_pairs} ({100*successful_relations/max(1,total_pairs):.1f}%)")
            if successful_relations > 0:
                self.log_processing(f"   Model Quality: Ready for large-gap filling predictions")
            else:
                self.log_processing(f"   Model Quality: Limited - insufficient relationships found")
        
        return True
    
    def _compute_property_relation(self, prop1, prop2):
        """Compute the relative relationship between two properties"""
        if SCIPY_AVAILABLE:
            from scipy import stats
        
        # Create masks for valid data points
        valid_mask = ~np.isnan(prop1) & ~np.isnan(prop2)
        
        if np.sum(valid_mask) < PHYSICAL_CONSTANTS.MIN_VALID_POINTS_FOR_RELATIONSHIP:
            # Not enough valid data points for a reliable relationship
            return {
                'type': 'insufficient_data',
                'valid_points': np.sum(valid_mask),
                'params': None
            }
        
        valid_prop1 = prop1[valid_mask]
        valid_prop2 = prop2[valid_mask]
        
        # Calculate statistics
        mean1 = np.mean(valid_prop1)
        mean2 = np.mean(valid_prop2)
        std1 = np.std(valid_prop1)
        std2 = np.std(valid_prop2)
        
        # Try different relationship models
        
        # 1. Linear relationship (y = mx + b)
        linear_relation = None
        try:
            if SCIPY_AVAILABLE:
                slope, intercept, r_value, _, _ = stats.linregress(valid_prop1, valid_prop2)
            else:
                # Fallback using numpy polyfit
                coeffs = np.polyfit(valid_prop1, valid_prop2, 1)
                slope, intercept = coeffs[0], coeffs[1]
                r_value = np.corrcoef(valid_prop1, valid_prop2)[0, 1]
            linear_relation = {
                'type': 'linear',
                'slope': slope,
                'intercept': intercept,
                'r_value': r_value,
                'correlation': np.corrcoef(valid_prop1, valid_prop2)[0, 1]
            }
        except Exception as e:
            warnings.warn(
                f"Linear relationship analysis failed: {str(e)}. "
                f"This may indicate insufficient data points, invalid values, or numerical instability. "
                f"Check data quality and ensure both curves have adequate overlap.",
                UserWarning
            )
            # Log for technical debugging
            if hasattr(self, 'log_processing'):
                self.log_processing(f"ERROR: Linear relationship analysis failed: {e}")
            linear_relation = {
                'type': 'linear_failed',
                'correlation': np.nan,
                'error_details': str(e),
                'remediation': 'Check data overlap and quality'
            }
        
        # 2. Power law relationship (y = a * x^b)
        power_relation = None
        try:
            # Filter out non-positive values for log transform
            positive_mask = (valid_prop1 > 0) & (valid_prop2 > 0)
            if np.sum(positive_mask) > PHYSICAL_CONSTANTS.MIN_VALID_POINTS_FOR_RELATIONSHIP:
                log_prop1 = np.log(valid_prop1[positive_mask])
                log_prop2 = np.log(valid_prop2[positive_mask])
                
                # Linear regression in log space
                if SCIPY_AVAILABLE:
                    slope, intercept, r_value, _, _ = stats.linregress(log_prop1, log_prop2)
                else:
                    coeffs = np.polyfit(log_prop1, log_prop2, 1)
                    slope, intercept = coeffs[0], coeffs[1]
                    r_value = np.corrcoef(log_prop1, log_prop2)[0, 1]
                power_relation = {
                    'type': 'power',
                    'coefficient': np.exp(intercept),
                    'exponent': slope,
                    'r_value': r_value
                }
            else:
                power_relation = {
                    'type': 'power_failed',
                    'correlation': np.nan
                }
        except Exception as e:
            warnings.warn(
                f"Power law relationship analysis failed: {str(e)}. "
                f"This often occurs when data contains negative values, insufficient positive data points, "
                f"or when the relationship is not power-law compatible. "
                f"Verify data ranges and consider data transformation.",
                UserWarning
            )
            # Log for technical debugging
            if hasattr(self, 'log_processing'):
                self.log_processing(f"ERROR: Power law relationship analysis failed: {e}")
            power_relation = {
                'type': 'power_failed',
                'correlation': np.nan,
                'error_details': str(e),
                'remediation': 'Check for negative values and data distribution'
            }
        
        # 3. Non-parametric relationship (based on quantile mapping)
        quantile_relation = None
        try:
            # Create empirical CDFs
            prop1_sorted = np.sort(valid_prop1)
            prop2_sorted = np.sort(valid_prop2)
            
            # Create percentile mapping
            percentiles = np.linspace(0, 1, 20)
            prop1_quantiles = np.quantile(valid_prop1, percentiles)
            prop2_quantiles = np.quantile(valid_prop2, percentiles)
            
            quantile_relation = {
                'type': 'quantile_mapping',
                'percentiles': percentiles,
                'prop1_quantiles': prop1_quantiles,
                'prop2_quantiles': prop2_quantiles,
                'r_value': np.corrcoef(valid_prop1, valid_prop2)[0, 1]  # Add r_value for comparison
            }
        except Exception as e:
            warnings.warn(
                f"Quantile regression analysis failed: {str(e)}. "
                f"This typically occurs with insufficient data points or extreme outliers. "
                f"Ensure adequate sample size (>50 points recommended) and check for data quality issues.",
                UserWarning
            )
            # Log for technical debugging  
            if hasattr(self, 'log_processing'):
                self.log_processing(f"ERROR: Quantile regression analysis failed: {e}")
            quantile_relation = {
                'type': 'quantile_failed',
                'correlation': np.nan,
                'error_details': str(e),
                'remediation': 'Ensure adequate sample size and check outliers'
            }
        
        # Select best relation based on correlation coefficient
        relations = [r for r in [linear_relation, power_relation, quantile_relation] if r is not None]
        valid_relations = [r for r in relations if 'r_value' in r]
        
        if valid_relations:
            best_relation = max(valid_relations, key=lambda x: abs(x.get('r_value', 0)))
            # Log model selection with quality metrics for scientific transparency
            if hasattr(self, 'log_processing'):
                correlation = abs(best_relation.get('r_value', 0))
                model_type = best_relation.get('type', 'unknown')
                self.log_processing(f"[MODEL SELECTION] Best relation: {model_type} | Correlation: {correlation:.3f}")
                if model_type == 'linear' and 'slope' in best_relation:
                    self.log_processing(f"   Linear Model: y = {best_relation['slope']:.3f}x + {best_relation.get('intercept', 0):.3f}")
                elif model_type == 'power' and 'exponent' in best_relation:
                    self.log_processing(f"   Power Model: y = {best_relation.get('coefficient', 1):.3f} * x^{best_relation['exponent']:.3f}")
                elif model_type == 'quantile':
                    self.log_processing(f"   Quantile Mapping: Non-parametric relationship model")
        else:
            # Fallback to basic statistical relationship
            best_relation = {
                'type': 'statistical',
                'mean_ratio': mean2 / (mean1 + 1e-10) if abs(mean1) > 1e-10 else 1.0,
                'std_ratio': std2 / (std1 + 1e-10) if abs(std1) > 1e-10 else 1.0
            }
            # Log statistical fallback
            if hasattr(self, 'log_processing'):
                self.log_processing(f"[MODEL SELECTION] Using statistical fallback (no strong correlation found)")
                self.log_processing(f"   Mean Ratio: {best_relation['mean_ratio']:.3f} | Std Ratio: {best_relation['std_ratio']:.3f}")
        
        return best_relation
    
    def fill_large_gap(self, curve_name, gap_start, gap_end, data, auxiliary_curves=None):
        """Fill a large gap using Relative Rock Properties
        
        Args:
            curve_name: Name of the curve with the gap
            gap_start, gap_end: Indices of the gap
            data: The curve data array with gap
            auxiliary_curves: Dictionary of other curves data
        
        Returns:
            Dict with filled values, uncertainty, and confidence
        """
        if not self.trained:
            return None
        
        gap_size = gap_end - gap_start
        
        # Initialize output arrays
        filled_values = np.full(gap_size, np.nan)
        uncertainty = np.full(gap_size, PHYSICAL_CONSTANTS.UNCERTAINTY_CEILING)  # Default high uncertainty
        confidence = np.full(gap_size, PHYSICAL_CONSTANTS.CONFIDENCE_FLOOR)
        
        # Check if auxiliary curves exist
        if not auxiliary_curves:
            return None
        
        # Find curves with data in the gap region
        reference_curves = []
        for other_curve, other_data in auxiliary_curves.items():
            if other_curve == curve_name:
                continue
                
            # Check if this curve has data in the gap region
            if other_data is None or len(other_data) <= gap_end:
                continue
                
            gap_region = other_data[gap_start:gap_end]
            valid_count = np.sum(~np.isnan(gap_region))
            valid_percentage = valid_count / len(gap_region) if len(gap_region) > 0 else 0
            
            if valid_percentage > PHYSICAL_CONSTANTS.CONFIDENCE_LEVELS["LOW"]:  # At least 50% valid data
                # Also check if we have a relationship with this curve
                relation_key = f"{curve_name}_{other_curve}" if curve_name < other_curve else f"{other_curve}_{curve_name}"
                if relation_key in self.property_relations:
                    reference_curves.append({
                        'name': other_curve,
                        'data': other_data,
                        'valid_percentage': valid_percentage,
                        'relation_key': relation_key
                    })
        
        if not reference_curves:
            return None
        
        # Sort reference curves by valid percentage
        reference_curves.sort(key=lambda x: x['valid_percentage'], reverse=True)
        
        # Create a weighted ensemble of predictions from all reference curves
        predictions = []
        weights = []
        
        for ref in reference_curves:
            # Get the relationship
            relation_key = ref['relation_key']
            relation = self.property_relations[relation_key]
            
            # Check if we need to swap the relationship direction
            swap_direction = relation_key.split('_')[0] != curve_name
            
            # Get reference data in gap region
            ref_data = ref['data'][gap_start:gap_end]
            
            # Apply the relationship to predict target values
            predicted = self._apply_relationship(ref_data, relation, swap_direction)
            
            # Calculate prediction quality based on valid data and relationship strength
            if 'r_value' in relation:
                relation_strength = abs(relation['r_value'])
            else:
                relation_strength = 0.5  # Default moderate strength
            
            # Weight by valid percentage and relationship strength
            weight = ref['valid_percentage'] * relation_strength
            
            predictions.append(predicted)
            weights.append(weight)
        
        # Normalize weights
        total_weight = sum(weights)
        if total_weight > 0:
            weights = [w / total_weight for w in weights]
        else:
            # If no valid weights, return None
            return None
        
        # Combine predictions
        for i in range(gap_size):
            weighted_values = []
            weighted_weights = []
            
            for pred, weight in zip(predictions, weights):
                if not np.isnan(pred[i]):
                    weighted_values.append(pred[i])
                    weighted_weights.append(weight)
            
            if weighted_values:
                # Weighted average for value
                total_w = sum(weighted_weights)
                if total_w > 1e-10:  # Avoid division by near-zero
                    filled_values[i] = sum(v * w for v, w in zip(weighted_values, weighted_weights)) / total_w
                    
                    # Uncertainty based on weighted variance
                    if len(weighted_values) > 1:
                        mean_val = filled_values[i]
                        variance = sum(w * (v - mean_val)**2 for v, w in zip(weighted_values, weighted_weights)) / (total_w + 1e-10)
                        uncertainty[i] = max(0.01, np.sqrt(variance))  # Add floor to uncertainty
                    else:
                        uncertainty[i] = 0.2  # Default uncertainty for single prediction
                    
                    # Confidence based on number of predictions and their weights
                    confidence[i] = min(0.9, total_w * 0.8)
        
        # Check if we have valid predictions
        valid_predictions = ~np.isnan(filled_values)
        valid_count = np.sum(valid_predictions)
        if valid_count < gap_size * 0.5:
            # Log insufficient predictions
            if hasattr(self, 'log_processing'):
                self.log_processing(f"[PREDICTION FAILURE] RRP gap filling insufficient: {valid_count}/{gap_size} points predicted")
            return None
        
        # Log successful prediction with quality metrics
        if hasattr(self, 'log_processing'):
            avg_confidence = np.mean(confidence[valid_predictions]) if valid_count > 0 else 0
            avg_uncertainty = np.mean(uncertainty[valid_predictions]) if valid_count > 0 else 1.0
            self.log_processing(f"[PREDICTION SUCCESS] RRP gap filling: {valid_count}/{gap_size} points")
            self.log_processing(f"   Reference Curves Used: {len(reference_curves)}")
            self.log_processing(f"   Average Confidence: {avg_confidence:.3f} | Average Uncertainty: {avg_uncertainty:.3f}")
            if len(reference_curves) > 0:
                best_ref = reference_curves[0]
                if 'r_value' in self.property_relations.get(best_ref['relation_key'], {}):
                    correlation = abs(self.property_relations[best_ref['relation_key']]['r_value'])
                    self.log_processing(f"   Best Reference: {best_ref['name']} (correlation: {correlation:.3f})")
        
        # Fill remaining NaN values using interpolation
        if np.any(np.isnan(filled_values)):
            valid_indices = np.nonzero(~np.isnan(filled_values))[0]
            nan_indices = np.nonzero(np.isnan(filled_values))[0]
            
            if len(valid_indices) > 1:
                # Use linear interpolation for remaining NaN values
                for nan_idx in nan_indices:
                    # Find nearest valid indices before and after
                    before_valid = valid_indices[valid_indices < nan_idx]
                    after_valid = valid_indices[valid_indices > nan_idx]
                    
                    if len(before_valid) > 0 and len(after_valid) > 0:
                        before_idx = before_valid[-1]
                        after_idx = after_valid[0]
                        
                        before_val = filled_values[before_idx]
                        after_val = filled_values[after_idx]
                        
                        # Linear interpolation
                        delta = after_idx - before_idx
                        if delta > 0:  # Avoid division by zero
                            alpha = (nan_idx - before_idx) / delta
                            filled_values[nan_idx] = before_val + alpha * (after_val - before_val)
                            
                            # Increase uncertainty for interpolated values
                            uncertainty[nan_idx] = max(uncertainty[before_idx], uncertainty[after_idx]) * 1.5
                            confidence[nan_idx] = min(confidence[before_idx], confidence[after_idx]) * 0.8
        
        return {
            'values': filled_values,
            'uncertainty': uncertainty,
            'confidence': confidence,
            'quality': np.mean(confidence)
        }
    
    def _apply_relationship(self, reference_data, relation, swap_direction):
        """Apply a relationship to predict values from reference data"""
        # Handle NaN values
        valid_mask = ~np.isnan(reference_data)
        predicted = np.full_like(reference_data, np.nan)
        
        if np.sum(valid_mask) == 0:
            return predicted
        
        ref_valid = reference_data[valid_mask]
        
        # Apply the appropriate relationship based on type
        if relation['type'] == 'linear':
            if not swap_direction:
                # Direct relationship: y = mx + b
                predicted[valid_mask] = relation['slope'] * ref_valid + relation['intercept']
            else:
                # Inverse relationship: x = (y - b) / m
                if abs(relation['slope']) > 1e-10:  # Avoid division by near-zero
                    predicted[valid_mask] = (ref_valid - relation['intercept']) / relation['slope']
                else:
                    # Can't invert a zero slope
                    return np.full_like(reference_data, np.nan)
                    
        elif relation['type'] == 'power':
            if not swap_direction:
                # Direct relationship: y = a * x^b
                predicted[valid_mask] = relation['coefficient'] * ref_valid ** relation['exponent']
            else:
                # Inverse relationship: x = (y/a)^(1/b)
                if abs(relation['exponent']) > 1e-10:  # Avoid division by near-zero
                    predicted[valid_mask] = (ref_valid / relation['coefficient']) ** (1 / relation['exponent'])
                else:
                    # Can't invert a zero exponent
                    return np.full_like(reference_data, np.nan)
                    
        elif relation['type'] == 'quantile_mapping':
            # For each valid reference value, find its percentile and map to target
            ref_quantiles = relation['prop1_quantiles'] if not swap_direction else relation['prop2_quantiles']
            target_quantiles = relation['prop2_quantiles'] if not swap_direction else relation['prop1_quantiles']
            
            for i, ref_val in enumerate(ref_valid):
                # Find position in sorted quantiles using interpolation
                pos = np.searchsorted(ref_quantiles, ref_val)
                idx = np.nonzero(valid_mask)[0][i]
                
                if pos == 0:
                    predicted[idx] = target_quantiles[0]
                elif pos >= len(ref_quantiles):
                    predicted[idx] = target_quantiles[-1]
                else:
                    # Linear interpolation between quantiles
                    alpha = (ref_val - ref_quantiles[pos-1]) / (ref_quantiles[pos] - ref_quantiles[pos-1] + 1e-10)
                    predicted[idx] = target_quantiles[pos-1] + alpha * (target_quantiles[pos] - target_quantiles[pos-1])
                
        elif relation['type'] == 'statistical':
            # Simple statistical relationship
            if not swap_direction:
                predicted[valid_mask] = ref_valid * relation['mean_ratio']
            else:
                if abs(relation['mean_ratio']) > 1e-10:  # Avoid division by near-zero
                    predicted[valid_mask] = ref_valid / relation['mean_ratio']
                else:
                    predicted[valid_mask] = ref_valid
                
        return predicted

    # Additional helper methods for the Enhanced RRP Model

    def _fit_robust_linear_model(self, prop1: np.ndarray, prop2: np.ndarray) -> Dict[str, Any]:
        """Fit robust linear model using RANSAC or Huber regression"""
        try:
            if SKLEARN_AVAILABLE and len(prop1) > 10:
                from sklearn.linear_model import HuberRegressor
                
                X = prop1.reshape(-1, 1)
                y = prop2
                
                # Use Huber regression for robustness to outliers
                huber = HuberRegressor(epsilon=1.35, max_iter=100)
                huber.fit(X, y)
                
                slope = huber.coef_[0]
                intercept = huber.intercept_
                
                # Calculate R² and RMSE
                y_pred = huber.predict(X)
                ss_res = np.sum((y - y_pred) ** 2)
                ss_tot = np.sum((y - np.mean(y)) ** 2)
                r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
                rmse = np.sqrt(np.mean((y - y_pred) ** 2))
                
                return {
                    'type': 'robust_linear',
                    'slope': slope,
                    'intercept': intercept,
                    'r_squared': r_squared,
                    'rmse': rmse,
                    'training_range': (np.min(prop1), np.max(prop1)),
                    'outlier_fraction': np.sum(huber.outliers_) / len(prop1) if hasattr(huber, 'outliers_') else 0
                }
            else:
                # Fallback to simple linear regression
                return self._fit_simple_linear_model(prop1, prop2)
                
        except Exception as e:
            warnings.warn(
                f"Cross-well model fitting failed: {str(e)}. "
                f"This may indicate incompatible data ranges, insufficient overlap between wells, "
                f"or numerical instability in the fitting algorithm. "
                f"Falling back to simple linear model. Check cross-well data alignment.",
                UserWarning
            )
            # Log for technical debugging
            if hasattr(self, 'log_processing'):
                self.log_processing(f"ERROR: Cross-well model fitting failed, using fallback: {e}")
            return self._fit_simple_linear_model(prop1, prop2)

    def _fit_simple_linear_model(self, prop1: np.ndarray, prop2: np.ndarray) -> Dict[str, Any]:
        """Fallback simple linear model"""
        try:
            # Use numpy polyfit for simple linear regression
            coeffs = np.polyfit(prop1, prop2, 1)
            slope, intercept = coeffs[0], coeffs[1]
            
            # Calculate R² and RMSE
            y_pred = slope * prop1 + intercept
            ss_res = np.sum((prop2 - y_pred) ** 2)
            ss_tot = np.sum((prop2 - np.mean(prop2)) ** 2)
            r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
            rmse = np.sqrt(np.mean((prop2 - y_pred) ** 2))
            
            return {
                'type': 'robust_linear',  # Keep same type for consistency
                'slope': slope,
                'intercept': intercept,
                'r_squared': r_squared,
                'rmse': rmse,
                'training_range': (np.min(prop1), np.max(prop1))
            }
            
        except Exception as e:
            warnings.warn(
                f"Simple linear model fitting failed: {str(e)}. "
                f"This indicates severe data issues such as all-constant values, "
                f"NaN/infinite values, or insufficient data points. "
                f"Check data quality and preprocessing steps.",
                UserWarning
            )
            # Log for technical debugging
            if hasattr(self, 'log_processing'):
                self.log_processing(f"ERROR: Simple linear model fitting failed: {e}")
            return {
                'type': 'linear_failed',
                'error_details': str(e),
                'remediation': 'Check for constant values, NaNs, or insufficient data'
            }

    def _fit_enhanced_power_model(self, prop1: np.ndarray, prop2: np.ndarray) -> Dict[str, Any]:
        """Fit enhanced power law model with bias correction"""
        try:
            # Filter out non-positive values for log transform
            positive_mask = (prop1 > 0) & (prop2 > 0)
            if np.sum(positive_mask) < 10:
                return {'type': 'power_failed'}
            
            prop1_pos = prop1[positive_mask]
            prop2_pos = prop2[positive_mask]
            
            # Transform to log space
            log_prop1 = np.log(prop1_pos)
            log_prop2 = np.log(prop2_pos)
            
            # Linear regression in log space: log(y) = log(a) + b*log(x)
            coeffs = np.polyfit(log_prop1, log_prop2, 1)
            log_a, b = coeffs[1], coeffs[0]  # intercept, slope
            a = np.exp(log_a)
            
            # Calculate R² in log space
            log_y_pred = b * log_prop1 + log_a
            ss_res = np.sum((log_prop2 - log_y_pred) ** 2)
            ss_tot = np.sum((log_prop2 - np.mean(log_prop2)) ** 2)
            r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
            
            # RMSE in original space
            y_pred = a * prop1_pos ** b
            rmse = np.sqrt(np.mean((prop2_pos - y_pred) ** 2))
            
            return {
                'type': 'enhanced_power',
                'coefficient': a,
                'exponent': b,
                'r_squared': r_squared,
                'rmse': rmse,
                'log_r_squared': r_squared,
                'training_range': (np.min(prop1_pos), np.max(prop1_pos)),
                'valid_fraction': np.sum(positive_mask) / len(prop1)
            }
            
        except Exception as e:
            warnings.warn(
                f"Enhanced power model fitting failed: {str(e)}. "
                f"This often occurs with negative/zero values, insufficient positive data, "
                f"or when data doesn't follow power-law behavior. "
                f"Check data distribution and consider log-scale analysis.",
                UserWarning
            )
            # Log for technical debugging
            if hasattr(self, 'log_processing'):
                self.log_processing(f"ERROR: Enhanced power model fitting failed: {e}")
            return {
                'type': 'power_failed',
                'error_details': str(e),
                'remediation': 'Check for positive values and power-law compatibility'
            }

    def _fit_piecewise_linear_model(self, prop1: np.ndarray, prop2: np.ndarray) -> Dict[str, Any]:
        """Fit piecewise linear model for complex relationships"""
        try:
            if len(prop1) < 20:  # Need sufficient data for piecewise fitting
                return self._fit_simple_linear_model(prop1, prop2)
            
            # Find optimal breakpoint using different percentiles
            best_r_squared = -1
            best_model = None
            
            for breakpoint_pct in [25, 33, 50, 67, 75]:
                breakpoint = np.percentile(prop1, breakpoint_pct)
                
                # Split data at breakpoint
                mask1 = prop1 <= breakpoint
                mask2 = prop1 > breakpoint
                
                if np.sum(mask1) < 5 or np.sum(mask2) < 5:
                    continue
                
                # Fit linear models to each segment
                try:
                    coeffs1 = np.polyfit(prop1[mask1], prop2[mask1], 1)
                    coeffs2 = np.polyfit(prop1[mask2], prop2[mask2], 1)
                    
                    # Calculate combined R²
                    y_pred = np.zeros_like(prop2)
                    y_pred[mask1] = coeffs1[0] * prop1[mask1] + coeffs1[1]
                    y_pred[mask2] = coeffs2[0] * prop1[mask2] + coeffs2[1]
                    
                    ss_res = np.sum((prop2 - y_pred) ** 2)
                    ss_tot = np.sum((prop2 - np.mean(prop2)) ** 2)
                    r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
                    
                    if r_squared > best_r_squared:
                        best_r_squared = r_squared
                        rmse = np.sqrt(np.mean((prop2 - y_pred) ** 2))
                        
                        best_model = {
                            'type': 'piecewise_linear',
                            'breakpoint': breakpoint,
                            'segment1_slope': coeffs1[0],
                            'segment1_intercept': coeffs1[1],
                            'segment2_slope': coeffs2[0],
                            'segment2_intercept': coeffs2[1],
                            'r_squared': r_squared,
                            'rmse': rmse,
                            'training_range': (np.min(prop1), np.max(prop1)),
                            'segment1_points': np.sum(mask1),
                            'segment2_points': np.sum(mask2)
                        }
                        
                except Exception:
                    continue
            
            return best_model if best_model else self._fit_simple_linear_model(prop1, prop2)
        
        except Exception as e:
            warnings.warn(
                f"Ensemble model training failed: {str(e)}. "
                f"This may indicate insufficient data for ensemble methods, "
                f"memory constraints, or incompatible sklearn version. "
                f"Falling back to simple linear model for reliability.",
                UserWarning
            )
            # Log for technical debugging
            if hasattr(self, 'log_processing'):
                self.log_processing(f"ERROR: Ensemble model training failed, using fallback: {e}")
            return self._fit_simple_linear_model(prop1, prop2)

    def _fit_enhanced_quantile_model(self, prop1: np.ndarray, prop2: np.ndarray) -> Dict[str, Any]:
        """Fit enhanced quantile-based model with smoothing"""
        try:
            # Create more quantiles for smoother mapping
            n_quantiles = min(20, len(prop1) // 5)  # Adaptive number of quantiles
            percentiles = np.linspace(0, 1, n_quantiles)
            
            prop1_quantiles = np.quantile(prop1, percentiles)
            prop2_quantiles = np.quantile(prop2, percentiles)
            
            # Apply smoothing to quantile mappings if we have enough points
            if n_quantiles > 10 and SCIPY_AVAILABLE:
                from scipy.interpolate import UnivariateSpline
                
                # Fit smoothing spline to quantile relationship
                spline = UnivariateSpline(prop1_quantiles, prop2_quantiles, s=0.1, k=3)
                
                # Evaluate spline at training points for R² calculation
                y_pred = spline(prop1)
                ss_res = np.sum((prop2 - y_pred) ** 2)
                ss_tot = np.sum((prop2 - np.mean(prop2)) ** 2)
                r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
                rmse = np.sqrt(np.mean((prop2 - y_pred) ** 2))
                
                return {
                    'type': 'enhanced_quantile',
                    'percentiles': percentiles,
                    'prop1_quantiles': prop1_quantiles,
                    'prop2_quantiles': prop2_quantiles,
                    'spline_coeffs': spline.get_coeffs(),
                    'spline_knots': spline.get_knots(),
                    'r_squared': r_squared,
                    'rmse': rmse,
                    'training_range': (np.min(prop1), np.max(prop1)),
                    'n_quantiles': n_quantiles,
                    'smoothed': True
                }
            else:
                # Basic quantile mapping without smoothing
                # Calculate R² using linear interpolation between quantiles
                y_pred = np.interp(prop1, prop1_quantiles, prop2_quantiles)
                ss_res = np.sum((prop2 - y_pred) ** 2)
                ss_tot = np.sum((prop2 - np.mean(prop2)) ** 2)
                r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
                rmse = np.sqrt(np.mean((prop2 - y_pred) ** 2))
                
                return {
                    'type': 'enhanced_quantile',
                    'percentiles': percentiles,
                    'prop1_quantiles': prop1_quantiles,
                    'prop2_quantiles': prop2_quantiles,
                    'r_squared': r_squared,
                    'rmse': rmse,
                    'training_range': (np.min(prop1), np.max(prop1)),
                    'n_quantiles': n_quantiles,
                    'smoothed': False
                }
                
        except Exception as e:
            pass
            return self._fit_simple_linear_model(prop1, prop2)

    def _cross_validate_model(self, prop1: np.ndarray, prop2: np.ndarray, model: Dict) -> Dict[str, float]:
        """Perform cross-validation to assess model reliability"""
        try:
            if len(prop1) < 10:
                # Not enough data for CV
                return {'mean_r2': 0, 'std_r2': 0, 'mean_rmse': float('inf'), 'std_rmse': 0}
            
            n_folds = min(5, len(prop1) // 3)  # Adaptive number of folds
            fold_size = len(prop1) // n_folds
            
            r2_scores = []
            rmse_scores = []
            
            for fold in range(n_folds):
                # Create train/test split
                test_start = fold * fold_size
                test_end = test_start + fold_size if fold < n_folds - 1 else len(prop1)
                
                test_mask = np.zeros(len(prop1), dtype=bool)
                test_mask[test_start:test_end] = True
                train_mask = ~test_mask
                
                if np.sum(train_mask) < 5 or np.sum(test_mask) < 2:
                    continue
                
                # Train on training set
                train_prop1 = prop1[train_mask]
                train_prop2 = prop2[train_mask]
                test_prop1 = prop1[test_mask]
                test_prop2 = prop2[test_mask]
                
                # Fit model type to training data
                if model['type'] == 'robust_linear':
                    fold_model = self._fit_simple_linear_model(train_prop1, train_prop2)
                elif model['type'] == 'enhanced_power':
                    fold_model = self._fit_enhanced_power_model(train_prop1, train_prop2)
                elif model['type'] == 'piecewise_linear':
                    fold_model = self._fit_piecewise_linear_model(train_prop1, train_prop2)
                elif model['type'] == 'enhanced_quantile':
                    fold_model = self._fit_enhanced_quantile_model(train_prop1, train_prop2)
                else:
                    fold_model = self._fit_simple_linear_model(train_prop1, train_prop2)
                
                # Predict on test set
                try:
                    test_pred = self._apply_model_for_cv(test_prop1, fold_model)
                    
                    if test_pred is not None and not np.any(np.isnan(test_pred)):
                        # Calculate metrics
                        ss_res = np.sum((test_prop2 - test_pred) ** 2)
                        ss_tot = np.sum((test_prop2 - np.mean(test_prop2)) ** 2)
                        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
                        rmse = np.sqrt(np.mean((test_prop2 - test_pred) ** 2))
                        
                        r2_scores.append(r2)
                        rmse_scores.append(rmse)
                        
                except Exception:
                    continue
            
            if r2_scores:
                cv_results = {
                    'mean_r2': np.mean(r2_scores),
                    'std_r2': np.std(r2_scores),
                    'mean_rmse': np.mean(rmse_scores),
                    'std_rmse': np.std(rmse_scores),
                    'n_folds_completed': len(r2_scores)
                }
                # Log cross-validation quality metrics
                if hasattr(self, 'log_processing'):
                    self.log_processing(f"[CROSS-VALIDATION] Model reliability assessment complete")
                    self.log_processing(f"   Mean R²: {cv_results['mean_r2']:.3f} ± {cv_results['std_r2']:.3f}")
                    self.log_processing(f"   Mean RMSE: {cv_results['mean_rmse']:.3f} ± {cv_results['std_rmse']:.3f}")
                    self.log_processing(f"   Folds Completed: {cv_results['n_folds_completed']}/{n_folds}")
                    if cv_results['mean_r2'] > 0.7:
                        self.log_processing(f"   Model Quality: Excellent (R² > 0.7)")
                    elif cv_results['mean_r2'] > 0.5:
                        self.log_processing(f"   Model Quality: Good (R² > 0.5)")
                    elif cv_results['mean_r2'] > 0.3:
                        self.log_processing(f"   Model Quality: Moderate (R² > 0.3)")
                    else:
                        self.log_processing(f"   Model Quality: Weak (R² < 0.3) - consider alternative models")
                return cv_results
            else:
                return {'mean_r2': 0, 'std_r2': 0, 'mean_rmse': float('inf'), 'std_rmse': 0, 'n_folds_completed': 0}
                
        except Exception as e:
            warnings.warn(
                f"Cross-validation analysis failed: {str(e)}. "
                f"This may be due to insufficient data for k-fold validation, "
                f"numerical instability, or sklearn compatibility issues. "
                f"Returning default metrics. Consider using simpler validation methods.",
                UserWarning
            )
            # Log for technical debugging
            if hasattr(self, 'log_processing'):
                self.log_processing(f"ERROR: Cross-validation analysis failed: {e}")
            return {
                'mean_r2': 0, 
                'std_r2': 0, 
                'mean_rmse': float('inf'), 
                'std_rmse': 0, 
                'n_folds_completed': 0,
                'error_details': str(e),
                'remediation': 'Check data size and sklearn installation'
            }

    def _apply_model_for_cv(self, x_values: np.ndarray, model: Dict) -> np.ndarray:
        """Apply model for cross-validation prediction"""
        try:
            if model['type'] == 'robust_linear':
                return model['slope'] * x_values + model['intercept']
                
            elif model['type'] == 'enhanced_power':
                return model['coefficient'] * x_values ** model['exponent']
                
            elif model['type'] == 'piecewise_linear':
                pred = np.zeros_like(x_values)
                mask1 = x_values <= model['breakpoint']
                mask2 = x_values > model['breakpoint']
                
                pred[mask1] = model['segment1_slope'] * x_values[mask1] + model['segment1_intercept']
                pred[mask2] = model['segment2_slope'] * x_values[mask2] + model['segment2_intercept']
                return pred
                
            elif model['type'] == 'enhanced_quantile':
                return np.interp(x_values, model['prop1_quantiles'], model['prop2_quantiles'])
                
            else:
                return None
                
        except Exception:
            return None

    def _calculate_model_complexity(self, model: Dict) -> float:
        """Calculate model complexity penalty factor"""
        complexity_scores = {
            'robust_linear': 1.0,
            'enhanced_power': 1.5,
            'piecewise_linear': 2.0,
            'enhanced_quantile': 1.2,
            'density_neutron_physics': 1.3,
            'archie_resistivity_porosity': 1.4
        }
        return complexity_scores.get(model['type'], 1.0)
    
    def _combine_predictions_with_uncertainty(self, predictions: List[np.ndarray], 
                                            weights: List[float], 
                                            uncertainties: List[np.ndarray]) -> Dict[str, np.ndarray]:
        """Combine multiple predictions with proper uncertainty propagation"""
        
        gap_size = len(predictions[0]) if predictions else 0
        combined_values = np.zeros(gap_size)
        combined_uncertainty = np.zeros(gap_size)
        combined_confidence = np.zeros(gap_size)
        
        # Normalize weights
        total_weight = sum(weights)
        if total_weight <= 0:
            return {
                'values': combined_values,
                'uncertainty': np.full(gap_size, 0.5),
                'confidence': np.full(gap_size, 0.1)
            }
        
        normalized_weights = [w / total_weight for w in weights]
        
        for i in range(gap_size):
            valid_predictions = []
            valid_weights = []
            valid_uncertainties = []
            
            # Collect valid predictions at this position
            for pred, weight, unc in zip(predictions, normalized_weights, uncertainties):
                if not np.isnan(pred[i]):
                    valid_predictions.append(pred[i])
                    valid_weights.append(weight)
                    valid_uncertainties.append(unc[i])
            
            if valid_predictions:
                # Weighted average for combined value
                total_w = sum(valid_weights)
                if total_w > 0:
                    combined_values[i] = sum(v * w for v, w in zip(valid_predictions, valid_weights)) / total_w
                    
                    # Uncertainty propagation: weighted variance + model uncertainty
                    if len(valid_predictions) > 1:
                        weighted_variance = sum(w * (v - combined_values[i])**2 for v, w in zip(valid_predictions, valid_weights)) / total_w
                        model_uncertainty = sum(w * unc**2 for w, unc in zip(valid_weights, valid_uncertainties)) / total_w
                        combined_uncertainty[i] = np.sqrt(weighted_variance + model_uncertainty)
                    else:
                        combined_uncertainty[i] = valid_uncertainties[0]
                    
                    # Confidence based on agreement and weight
                    combined_confidence[i] = min(0.95, total_w * 0.9)
                else:
                    combined_values[i] = valid_predictions[0]
                    combined_uncertainty[i] = valid_uncertainties[0]
                    combined_confidence[i] = 0.3
            else:
                # No valid predictions
                combined_values[i] = np.nan
                combined_uncertainty[i] = 1.0
                combined_confidence[i] = 0.0
        
        return {
            'values': combined_values,
            'uncertainty': combined_uncertainty,
            'confidence': combined_confidence
        }


# Create global instance for use throughout the application
ARCHIE_CALCULATOR = ArchieEquationCalculator()

